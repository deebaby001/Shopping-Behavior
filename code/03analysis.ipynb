{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis I\n",
    "\n",
    "Lastly, we will answer the following questions using pandas methods: \n",
    "\n",
    "* What are the most popular colors by season?\n",
    "* What is the most popular clothing item by season?\n",
    "* What is the effect of promo-codes on the dollar-amount of purchases?\n",
    "* When do users leave a review?\n",
    "* Do states vary in the items they purchase in the Fall?\n",
    "\n",
    "Utilize the documentation provided in each code-block. When you are done with this section of the project, validate that your output matches the screenshot provided in the `docs/part3.md` file and answer the questions located underneath `Data Analysis II` in your own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load `data/processed/shopping_cleaned.csv` as a pandas dataframe\n",
    "\n",
    "df=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a dataframe pivot table where \"Season\" is your column, \"Color\" is your index, and \"Location\" is your value (this value is arbitrary)\n",
    "# use the len function as the \"aggfunc\" parameter.\n",
    "# Save this pivot table to a new variable\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html\n",
    "\n",
    "Nu_1_pivot_table = df.pivot_table(index='Color', columns='Season', values='Location', aggfunc=len, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season                Fall  Spring  Summer  Winter\n",
      "Color                                             \n",
      "Aubergine              101       4      14     144\n",
      "Baby blue               17      83      99      24\n",
      "Black                  103       5      12     155\n",
      "Brick red              103       7      14     140\n",
      "Brown                  117       5       5     120\n",
      "Burnt orange           110       4      10     138\n",
      "Fuchsia                  5      59     103      21\n",
      "Lavender                19      63     120      13\n",
      "Lemon yellow            11      62     112      18\n",
      "Mauve                  102       6      12     120\n",
      "Muted mustard yellow   103      10      15     110\n",
      "Pale peach              13      68     104      15\n",
      "Periwinkle               9      63     105       9\n",
      "Ruby Red               112       4      10     132\n",
      "Terra cotta            108       5      15     131\n",
      "Turquoise               10      60      96      19\n",
      "White                   13      73      96      12\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display this pivot table\n",
    "\n",
    "print(Nu_1_pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Brown                   117\n",
      "Ruby Red                112\n",
      "Burnt orange            110\n",
      "Terra cotta             108\n",
      "Black                   103\n",
      "Brick red               103\n",
      "Muted mustard yellow    103\n",
      "Mauve                   102\n",
      "Aubergine               101\n",
      "Lavender                 19\n",
      "Baby blue                17\n",
      "White                    13\n",
      "Pale peach               13\n",
      "Lemon yellow             11\n",
      "Turquoise                10\n",
      "Periwinkle                9\n",
      "Fuchsia                   5\n",
      "Name: Fall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Fall\" column from this pivot table and display the sort order in descending order\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Fall'].sort_values(ascending=False)\n",
    "\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Black                   155\n",
      "Aubergine               144\n",
      "Brick red               140\n",
      "Burnt orange            138\n",
      "Ruby Red                132\n",
      "Terra cotta             131\n",
      "Brown                   120\n",
      "Mauve                   120\n",
      "Muted mustard yellow    110\n",
      "Baby blue                24\n",
      "Fuchsia                  21\n",
      "Turquoise                19\n",
      "Lemon yellow             18\n",
      "Pale peach               15\n",
      "Lavender                 13\n",
      "White                    12\n",
      "Periwinkle                9\n",
      "Name: Winter, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Winter\" column from this pivot table and display the sort order in descending order.\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Winter'].sort_values(ascending=False)\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Baby blue               83\n",
      "White                   73\n",
      "Pale peach              68\n",
      "Lavender                63\n",
      "Periwinkle              63\n",
      "Lemon yellow            62\n",
      "Turquoise               60\n",
      "Fuchsia                 59\n",
      "Muted mustard yellow    10\n",
      "Brick red                7\n",
      "Mauve                    6\n",
      "Brown                    5\n",
      "Black                    5\n",
      "Terra cotta              5\n",
      "Burnt orange             4\n",
      "Ruby Red                 4\n",
      "Aubergine                4\n",
      "Name: Spring, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Spring\" column from this pivot table and display the sort order in descending order\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Spring'].sort_values(ascending=False)\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Lavender                120\n",
      "Lemon yellow            112\n",
      "Periwinkle              105\n",
      "Pale peach              104\n",
      "Fuchsia                 103\n",
      "Baby blue                99\n",
      "Turquoise                96\n",
      "White                    96\n",
      "Muted mustard yellow     15\n",
      "Terra cotta              15\n",
      "Brick red                14\n",
      "Aubergine                14\n",
      "Mauve                    12\n",
      "Black                    12\n",
      "Burnt orange             10\n",
      "Ruby Red                 10\n",
      "Brown                     5\n",
      "Name: Summer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Summer\" column from this pivot table and display the sort order in descending order\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Summer'].sort_values(ascending=False)\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Season\n",
       "Fall          Brown\n",
       "Spring    Baby blue\n",
       "Summer     Lavender\n",
       "Winter        Black\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Using the \"idmax\" method, get the index with the maximum value for each column\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html\n",
    "\n",
    "Nu_1_pivot_table.idxmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a dataframe pivot table where \"Season\" is your column, \"Item Purchased\" is your index, and \"Location\" is your value (this value is arbitrary)\n",
    "# use the len function as the \"aggfunc\" parameter.\n",
    "# Save this pivot table to a new variable and display it\n",
    "\n",
    "Second_pivot_table = df.pivot_table(index='Item Purchased', columns='Season', values='Location', aggfunc=len, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Season\n",
       "Fall              Socks\n",
       "Spring    Running Shoes\n",
       "Summer           Shorts\n",
       "Winter         Leggings\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Using the \"idmax\" method, get the index with the maximum value for each column on the pivot table containing clothing items & season\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html\n",
    "\n",
    "Second_pivot_table.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create two data-frames for promo-code users and non-promo-code users using boolean indexing\n",
    "# Save these two dataframes into seperate variables \n",
    "# Documentation: https://pandas.pydata.org/docs/user_guide/indexing.html#boolean-indexing\n",
    "# Hint: Users that have used a promo code have the value \"Yes\" in the column \"Promo Code Used\"\n",
    "\n",
    "#The following code is trying to do:\n",
    "#Make 2 New DataFrame for the original data\n",
    "#Using those 2 dataframes create 2 new sets of dataframes that are reading the \"Promo Code Used\" field\n",
    "#Evaluating the column to determine \"TRUE\" or \"FALSE\"\n",
    "#That is \"Yes\" or \"No\" indicating rather or not the promo code was used.\n",
    "\n",
    "promo_code_users_df = df[df['Promo Code Used'] == True]\n",
    "non_promo_code_users_df = df[df['Promo Code Used'] == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 13)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the shape of the promo code users dataframe. This should be (1373, 13)\n",
    "\n",
    "print(promo_code_users_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the average purchase size of promo code users dataframe. This should be 50.06747998236351\n",
    "\n",
    "average_purchase_size = promo_code_users_df['Promo Code Used'].mean()\n",
    "print(average_purchase_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 13)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the shape of the non promo code users dataframe. This should be (1785, 13)\n",
    "\n",
    "print(non_promo_code_users_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the average purchase size of non promo code users dataframe. This should be 30.155750765104113\n",
    "\n",
    "average_purchase_size = non_promo_code_users_df['Promo Code Used'].mean()\n",
    "print(average_purchase_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate a null hypothesis regarding the dollar amount spent between promo-code users & non-promo-code users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One null hypothesis could be that the total dollars that those customer with a promo code (promo code user) would spend more money on average versus the customer that did not have a promo code (non-promo code user)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate an alternative hypothesis regarding the dollar amount spent between promo-code users & non-promo-code users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, if the customer did have a promo code, it may only be applicable to a certain amount of money that the customer will have to spend in order to even have the ability to use the promo code. e.g a promo code will be applicable for all orders OVER $ 200.00. Therefore, if the customer is unable to afford to purchase that amount of merchandise totalling over $ 200.00 they will be automatically restricted from using the promo code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNABLE TO EXECUTE\n",
    "# TODO: Using the \"ttest_ind\" method from \"scipy.stats\", run a T-Test between the dollar amount spent of promo-code users and non promo-code users\n",
    "# The t-statistic you should observe is 93.2464714350831\n",
    "# Documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
    "\n",
    "#ttest for 1.) dollar amount spent of promo-code users and 2.) non promo-code users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-value:  -3.8663000222524073\n",
      "p-value:  0.002242872583106794\n"
     ]
    }
   ],
   "source": [
    "#Added my own code for an example\n",
    "\n",
    "#Calculating the t-value and p-value of 2 indicators A1 and B1\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming that A1 and B1 are your data\n",
    "A1 = [2, 18, 16, 3, 9, 12, 14]\n",
    "B1 = [32, 12, 34, 23, 30, 19, 26]\n",
    "\n",
    "t_value, p_value = stats.ttest_ind(A1, B1)\n",
    "\n",
    "print(\"t-value: \", t_value)\n",
    "print(\"p-value: \", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation:  3.155817433482074\n"
     ]
    }
   ],
   "source": [
    "#Calculating the Standard Deviation of a t-test\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Suggested dataset\n",
    "data = [10, 13, 11, 15, 20, 14, 11]\n",
    "\n",
    "# Calculate standard deviation\n",
    "std_dev = np.std(data)\n",
    "\n",
    "print(\"Standard Deviation: \", std_dev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4.0\n",
      "1    4.0\n",
      "2    5.0\n",
      "3    5.0\n",
      "4    4.0\n",
      "Name: Review Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Group your dataframe according to the \"Review Rating\" column. This should produce two groups for the values \"Missing\" & \"Present\"\n",
    "# Save this grouped dataframe into a new variable named \"g_review\"\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\n",
    "\n",
    "df=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')\n",
    "g_review = df.groupby('Review Rating')\n",
    "print(df['Review Rating'].head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([1.0, 2.0, 4.0, 5.0])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print out the keys of this dataframe for validation. This should output \"dict_keys(['Missing', 'Present'])\"\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.keys.html\n",
    "\n",
    "print(g_review.groups.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Purchase Amount (USD)        Age  Previous Purchases\n",
      "Review Rating                                                      \n",
      "1.0                        27.176400  31.933333            5.600000\n",
      "2.0                        30.879706  32.969697            7.757576\n",
      "4.0                        30.394100  35.741036            8.000000\n",
      "5.0                        30.604964  32.891156            8.108844\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate the average of the \"Purchase Amount (USD)\", \"Age\", and \"Previous Purchases\" columns in our grouped dataframe\n",
    "# output the values for display\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
    "# Documentation: https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n",
    "\n",
    "#The average values from the grouped by range for 'Purchase Amount (USD)', 'Age', 'Previous Purchases\n",
    "\n",
    "average_values = g_review[['Purchase Amount (USD)', 'Age', 'Previous Purchases']].mean()\n",
    "\n",
    "# Print the average values\n",
    "print(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Low\n",
      "1    High\n",
      "2     Low\n",
      "3     Low\n",
      "4     Low\n",
      "Name: Prev Purchase Group, dtype: category\n",
      "Categories (2, object): ['Low' < 'High']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a new column called \"Prev Purchase Group\" on your original dataframe which seperates your dataframe into \n",
    "# two groups of shoppers based on their \"Previous Purchases\" column using the \"pd.cut\" method. \n",
    "# Ensure that you are only creating 2 \"bins\" and label these respective bins as [\"Low\", \"High\"]\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n",
    "\n",
    "#df_copy=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')\n",
    "\n",
    "#df=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')\n",
    "\n",
    "#df['Prev Purchase Group'] = pd.cut(df['Previous Purchases'], bins=2, labels=['Low', 'High'])\n",
    "\n",
    "print(df['Prev Purchase Group'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Rating\n",
      "4.0    174\n",
      "5.0     99\n",
      "2.0     49\n",
      "1.0     12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO: Using the \"value_counts\" function, count how many Missing & Present values are in the \"Low\" group\n",
    "# Display this value for analysis \n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "# Hint: You will have to use Boolean Indexing\n",
    "\n",
    "#Show the 'Low' group\n",
    "low_group = df[df['Prev Purchase Group'] == 'Low']\n",
    "\n",
    "#Count the 'Missing' and 'Present' values\n",
    "value_counts = low_group['Review Rating'].value_counts()\n",
    "\n",
    "#Print the counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Rating\n",
      "4.0    77\n",
      "5.0    48\n",
      "2.0    17\n",
      "1.0     3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Using the \"value_counts\" function, count how many Missing & Present values are in the \"High\" group\n",
    "# Display this value for analysis \n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "# Hint: You will have to use Boolean Indexing\n",
    "\n",
    "#Show the 'High' group\n",
    "high_group = df[df['Prev Purchase Group'] == 'High']\n",
    "\n",
    "#Count the 'Missing' and 'Present' values\n",
    "value_counts = high_group['Review Rating'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis II\n",
    "\n",
    "In the next section, answer the primary analytical questions in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "What are the top three colors for Fall & Winter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 colors for Fall and Winter are: Fall ( there were some ties so I listed them): \n",
    "Fall\n",
    "Brown                   117\n",
    "Ruby Red                112\n",
    "Burnt orange            110\n",
    "\n",
    "Winter\n",
    "Black                   155\n",
    "Aubergine               144\n",
    "Brick red               140\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "What are the top three colors for Spring & Summer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 colors for Spring and Summer are: \n",
    "Spring: \n",
    "Baby blue               83\n",
    "White                   73\n",
    "Pale peach              68\n",
    "\n",
    "\n",
    "Summer:\n",
    "Lavender                120\n",
    "Lemon yellow            112\n",
    "Periwinkle              105\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "What is the most popular clothing item by season?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Season\n",
    "Fall              Socks\n",
    "Spring    Running Shoes\n",
    "Summer       Sunglasses\n",
    "Winter         Leggings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "Observing the p-value that we got when running our t-test between promo-code and non-promo-code users, what can we conclude regarding our null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Verdict is still out! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "Observe the `value_counts` output for the \"Review Rating\" column for both your \"High\" and \"Low\" groups. Proportionally speaking, which group is more likely to leave a review? Why might this be happening from the \"human\"-perspective? Rationalizations are ok at this point, even if they aren't backed up by data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that the group most likely to leave a review at all is: Low group. Our dollars count for something, no matter how little we spend. I think that the economy is driving a lot of these factors. Everything is more expensive like 2-3 times as great as it was 2-3 years ago. And even when you are paying less, you are still expecting to have Great Value, Great Product Satisfaction, Great Reliability from your purchase. I would be interested to learn what the ratings were prior to the pandemic and even prior to 2000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
