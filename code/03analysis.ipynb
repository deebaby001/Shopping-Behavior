{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis I\n",
    "\n",
    "Lastly, we will answer the following questions using pandas methods: \n",
    "\n",
    "* What are the most popular colors by season?\n",
    "* What is the most popular clothing item by season?\n",
    "* What is the effect of promo-codes on the dollar-amount of purchases?\n",
    "* When do users leave a review?\n",
    "* Do states vary in the items they purchase in the Fall?\n",
    "\n",
    "Utilize the documentation provided in each code-block. When you are done with this section of the project, validate that your output matches the screenshot provided in the `docs/part3.md` file and answer the questions located underneath `Data Analysis II` in your own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3158, 13)\n"
     ]
    }
   ],
   "source": [
    "# TODO: load `data/processed/shopping_cleaned.csv` as a pandas dataframe\n",
    "# df=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')\n",
    "\n",
    "df=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/data/processed/shopping_cleaned.csv')\n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a dataframe pivot table where \"Season\" is your column, \"Color\" is your index, and \"Location\" is your value (this value is arbitrary)\n",
    "# use the len function as the \"aggfunc\" parameter.\n",
    "# Save this pivot table to a new variable\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html\n",
    "\n",
    "Nu_1_pivot_table = df.pivot_table(index='Color', columns='Season', values='Location', aggfunc=len, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season                Fall  Spring  Summer  Winter\n",
      "Color                                             \n",
      "Aubergine               83       2      13     111\n",
      "Baby blue               16      69      84      21\n",
      "Black                   84       5       9     124\n",
      "Brick red               88       7      12     110\n",
      "Brown                   97       5       3      89\n",
      "Burnt orange            93       4       5     112\n",
      "Fuchsia                  3      45      78      18\n",
      "Lavender                13      55     102       6\n",
      "Lemon yellow             9      47      98      13\n",
      "Mauve                   86       5       7      95\n",
      "Muted mustard yellow    84       8      13      87\n",
      "Pale peach               9      52      81      15\n",
      "Periwinkle               9      54      82       8\n",
      "Ruby Red                90       3       8     107\n",
      "Terra cotta             91       4      15     101\n",
      "Turquoise                7      49      74      16\n",
      "White                   10      63      81      11\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display this pivot table\n",
    "\n",
    "print(Nu_1_pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Brown                   97\n",
      "Burnt orange            93\n",
      "Terra cotta             91\n",
      "Ruby Red                90\n",
      "Brick red               88\n",
      "Mauve                   86\n",
      "Black                   84\n",
      "Muted mustard yellow    84\n",
      "Aubergine               83\n",
      "Baby blue               16\n",
      "Lavender                13\n",
      "White                   10\n",
      "Periwinkle               9\n",
      "Pale peach               9\n",
      "Lemon yellow             9\n",
      "Turquoise                7\n",
      "Fuchsia                  3\n",
      "Name: Fall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Fall\" column from this pivot table and display the sort order in descending order\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Fall'].sort_values(ascending=False)\n",
    "\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Black                   124\n",
      "Burnt orange            112\n",
      "Aubergine               111\n",
      "Brick red               110\n",
      "Ruby Red                107\n",
      "Terra cotta             101\n",
      "Mauve                    95\n",
      "Brown                    89\n",
      "Muted mustard yellow     87\n",
      "Baby blue                21\n",
      "Fuchsia                  18\n",
      "Turquoise                16\n",
      "Pale peach               15\n",
      "Lemon yellow             13\n",
      "White                    11\n",
      "Periwinkle                8\n",
      "Lavender                  6\n",
      "Name: Winter, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Winter\" column from this pivot table and display the sort order in descending order.\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Winter'].sort_values(ascending=False)\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Baby blue               69\n",
      "White                   63\n",
      "Lavender                55\n",
      "Periwinkle              54\n",
      "Pale peach              52\n",
      "Turquoise               49\n",
      "Lemon yellow            47\n",
      "Fuchsia                 45\n",
      "Muted mustard yellow     8\n",
      "Brick red                7\n",
      "Mauve                    5\n",
      "Brown                    5\n",
      "Black                    5\n",
      "Burnt orange             4\n",
      "Terra cotta              4\n",
      "Ruby Red                 3\n",
      "Aubergine                2\n",
      "Name: Spring, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Spring\" column from this pivot table and display the sort order in descending order\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Spring'].sort_values(ascending=False)\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color\n",
      "Lavender                102\n",
      "Lemon yellow             98\n",
      "Baby blue                84\n",
      "Periwinkle               82\n",
      "Pale peach               81\n",
      "White                    81\n",
      "Fuchsia                  78\n",
      "Turquoise                74\n",
      "Terra cotta              15\n",
      "Muted mustard yellow     13\n",
      "Aubergine                13\n",
      "Brick red                12\n",
      "Black                     9\n",
      "Ruby Red                  8\n",
      "Mauve                     7\n",
      "Burnt orange              5\n",
      "Brown                     3\n",
      "Name: Summer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the \"Summer\" column from this pivot table and display the sort order in descending order\n",
    "\n",
    "sorted_column = Nu_1_pivot_table['Summer'].sort_values(ascending=False)\n",
    "print(sorted_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Season\n",
       "Fall          Brown\n",
       "Spring    Baby blue\n",
       "Summer     Lavender\n",
       "Winter        Black\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Using the \"idmax\" method, get the index with the maximum value for each column\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html\n",
    "\n",
    "Nu_1_pivot_table.idxmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a dataframe pivot table where \"Season\" is your column, \"Item Purchased\" is your index, and \"Location\" is your value (this value is arbitrary)\n",
    "# use the len function as the \"aggfunc\" parameter.\n",
    "# Save this pivot table to a new variable and display it\n",
    "\n",
    "Second_pivot_table = df.pivot_table(index='Item Purchased', columns='Season', values='Location', aggfunc=len, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Season\n",
       "Fall           Backpack\n",
       "Spring    Running Shoes\n",
       "Summer           Shorts\n",
       "Winter         Leggings\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Using the \"idmax\" method, get the index with the maximum value for each column on the pivot table containing clothing items & season\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html\n",
    "\n",
    "Second_pivot_table.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create two data-frames for promo-code users and non-promo-code users using boolean indexing\n",
    "# Save these two data frames into separate variables \n",
    "# Documentation: https://pandas.pydata.org/docs/user_guide/indexing.html#boolean-indexing\n",
    "# Hint: Users that have used a promo code have the value \"Yes\" in the column \"Promo Code Used\"\n",
    "\n",
    "#The following code is trying to do:\n",
    "#Make 2 New DataFrame for the original data\n",
    "#Using those 2 data frames create 2 new sets of data  frames that are reading the \"Promo Code Used\" field\n",
    "#Evaluating the column to determine \"TRUE\" or \"FALSE\"\n",
    "#That is \"Yes\" or \"No\" indicating rather or not the promo code was used.\n",
    "\n",
    "\n",
    "#Make a 2 copies of the data frame\n",
    "df_backcopy_1 = df.copy()\n",
    "df_backcopy_2 = df.copy()\n",
    "\n",
    "\n",
    "promo_code_users_df = df_backcopy_1[df_backcopy_1['Promo Code Used'] == 'Yes']\n",
    "non_promo_code_users_df = df_backcopy_2[df_backcopy_2['Promo Code Used'] == 'No']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1373, 13)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the shape of the promo code users dataframe. This should be (1373, 13)\n",
    "\n",
    "print(promo_code_users_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.06747998236351\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the average purchase size of promo code users dataframe. This should be 50.06747998236351\n",
    "\n",
    "# Filter the DataFrame to include only the rows where a promo code was used\n",
    "promo_code_users = df_backcopy_1[df_backcopy_1['Promo Code Used'] == 'Yes']\n",
    "\n",
    "# Calculate and print the average purchase size\n",
    "average_purchase_size = promo_code_users['Purchase Amount (USD)'].mean()\n",
    "\n",
    "\n",
    "print(average_purchase_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 13)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the shape of the non promo code users dataframe. This should be (1785, 13)\n",
    "\n",
    "print(non_promo_code_users_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.155750765104113\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the average purchase size of non promo code users dataframe. This should be 30.155750765104113\n",
    "\n",
    "\n",
    "# Filter the DataFrame to include only the rows where a promo code was used\n",
    "non_promo_code_users = df_backcopy_2[df_backcopy_2['Promo Code Used'] == 'No']\n",
    "\n",
    "# Calculate and print the average purchase size\n",
    "average_purchase_size = non_promo_code_users['Purchase Amount (USD)'].mean()\n",
    "print(average_purchase_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate a null hypothesis regarding the dollar amount spent between promo-code users & non-promo-code users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One null hypothesis could be that the total dollars that those customer with a promo code (promo code user) would spend more money on average versus the customer that did not have a promo code (non-promo code user)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate an alternative hypothesis regarding the dollar amount spent between promo-code users & non-promo-code users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, if the customer did have a promo code, it may only be applicable to a certain amount of money that the customer will have to spend in order to even have the ability to use the promo code. e.g a promo code will be applicable for all orders OVER 200.00 Dollars. Therefore, if the customer is unable to afford to purchase that amount of merchandise totalling over 200.00 Dollars, they will be automatically restricted from using the promo code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNABLE TO EXECUTE\n",
    "# TODO: Using the \"ttest_ind\" method from \"scipy.stats\", run a T-Test between the dollar amount spent of promo-code users and non promo-code users\n",
    "# The t-statistic you should observe is 93.2464714350831\n",
    "# Documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
    "\n",
    "#ttest for 1.) dollar amount spent of promo-code users and 2.) non promo-code users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added my own code for an example\n",
    "\n",
    "#Calculating the t-value and p-value of 2 indicators A1 and B1\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming that A1 and B1 are your data\n",
    "A1 = [2, 18, 16, 3, 9, 12, 14]\n",
    "B1 = [32, 12, 34, 23, 30, 19, 26]\n",
    "\n",
    "t_value, p_value = stats.ttest_ind(A1, B1)\n",
    "\n",
    "print(\"t-value: \", t_value)\n",
    "print(\"p-value: \", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Standard Deviation of a t-test\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Suggested dataset\n",
    "data = [10, 13, 11, 15, 20, 14, 11]\n",
    "\n",
    "# Calculate standard deviation\n",
    "std_dev = np.std(data)\n",
    "\n",
    "print(\"Standard Deviation: \", std_dev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Group your dataframe according to the \"Review Rating\" column. This should produce two groups for the values \"Missing\" & \"Present\"\n",
    "# Save this grouped dataframe into a new variable named \"g_review\"\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\n",
    "\n",
    "df=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')\n",
    "g_review = df.groupby('Review Rating')\n",
    "print(df['Review Rating'].head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print out the keys of this dataframe for validation. This should output \"dict_keys(['Missing', 'Present'])\"\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.keys.html\n",
    "\n",
    "print(g_review.groups.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the average of the \"Purchase Amount (USD)\", \"Age\", and \"Previous Purchases\" columns in our grouped dataframe\n",
    "# output the values for display\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
    "# Documentation: https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n",
    "\n",
    "#The average values from the grouped by range for 'Purchase Amount (USD)', 'Age', 'Previous Purchases\n",
    "\n",
    "average_values = g_review[['Purchase Amount (USD)', 'Age', 'Previous Purchases']].mean()\n",
    "\n",
    "# Print the average values\n",
    "print(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a new column called \"Prev Purchase Group\" on your original dataframe which seperates your dataframe into \n",
    "# two groups of shoppers based on their \"Previous Purchases\" column using the \"pd.cut\" method. \n",
    "# Ensure that you are only creating 2 \"bins\" and label these respective bins as [\"Low\", \"High\"]\n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n",
    "\n",
    "#df_copy=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')\n",
    "\n",
    "#df=pd.read_csv('C:/Users/deema/Desktop/Lab4/shopping-behavior/code/shopping_cleaned.csv')\n",
    "\n",
    "#df['Prev Purchase Group'] = pd.cut(df['Previous Purchases'], bins=2, labels=['Low', 'High'])\n",
    "\n",
    "print(df['Prev Purchase Group'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: Using the \"value_counts\" function, count how many Missing & Present values are in the \"Low\" group\n",
    "# Display this value for analysis \n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "# Hint: You will have to use Boolean Indexing\n",
    "\n",
    "#Show the 'Low' group\n",
    "low_group = df[df['Prev Purchase Group'] == 'Low']\n",
    "\n",
    "#Count the 'Missing' and 'Present' values\n",
    "value_counts = low_group['Review Rating'].value_counts()\n",
    "\n",
    "#Print the counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using the \"value_counts\" function, count how many Missing & Present values are in the \"High\" group\n",
    "# Display this value for analysis \n",
    "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "# Hint: You will have to use Boolean Indexing\n",
    "\n",
    "#Show the 'High' group\n",
    "high_group = df[df['Prev Purchase Group'] == 'High']\n",
    "\n",
    "#Count the 'Missing' and 'Present' values\n",
    "value_counts = high_group['Review Rating'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis II\n",
    "\n",
    "In the next section, answer the primary analytical questions in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "What are the top three colors for Fall & Winter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 colors for Fall and Winter are: Fall ( there were some ties so I listed them): \n",
    "Fall\n",
    "Brown                   117\n",
    "Ruby Red                112\n",
    "Burnt orange            110\n",
    "\n",
    "Winter\n",
    "Black                   155\n",
    "Aubergine               144\n",
    "Brick red               140\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "What are the top three colors for Spring & Summer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 colors for Spring and Summer are: \n",
    "Spring: \n",
    "Baby blue               83\n",
    "White                   73\n",
    "Pale peach              68\n",
    "\n",
    "\n",
    "Summer:\n",
    "Lavender                120\n",
    "Lemon yellow            112\n",
    "Periwinkle              105\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "What is the most popular clothing item by season?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Season\n",
    "Fall              Socks\n",
    "Spring    Running Shoes\n",
    "Summer       Sunglasses\n",
    "Winter         Leggings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "Observing the p-value that we got when running our t-test between promo-code and non-promo-code users, what can we conclude regarding our null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Verdict is still out! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "Observe the `value_counts` output for the \"Review Rating\" column for both your \"High\" and \"Low\" groups. Proportionally speaking, which group is more likely to leave a review? Why might this be happening from the \"human\"-perspective? Rationalizations are ok at this point, even if they aren't backed up by data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that the group most likely to leave a review at all is: Low group. Our dollars count for something, no matter how little we spend. I think that the economy is driving a lot of these factors. Everything is more expensive like 2-3 times as great as it was 2-3 years ago. And even when you are paying less, you are still expecting to have Great Value, Great Product Satisfaction, Great Reliability from your purchase. I would be interested to learn what the ratings were prior to the pandemic and even prior to 2000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
